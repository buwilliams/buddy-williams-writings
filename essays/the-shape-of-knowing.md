# The Shape of Knowing

*An Epistemology for Finite Beings*

**Buddy Williams** · February 2026

---

I've spent most of my life feeling like I think differently than the people around me.

Not better — just differently. When someone presents an argument, my first instinct isn't to agree or disagree. It's to ask: *what would have to be true for this to work?* When a belief feels solid, I poke at it: *where does this break?* When someone dismisses a wild idea, I wonder: *what if they're not wrong, just early?*

For a long time, I thought this made me difficult. Now I think it makes me honest about what knowing actually is.

This essay is my attempt to name the shape of knowing as I've come to understand it — not as a set of rules, but as a posture toward reality. It ties together ideas I've explored separately: the cyclical rhythm of rationality, why truth emerges from utility rather than the reverse, why hypotheticals matter even when they annoy people, and what any of this has to do with technology, human futures, and minds far more powerful than ours.

If it works, it should feel less like a philosophy lecture and more like a map you can actually use.

---

## The Problem with How We Think About Thinking

The dominant story about rationality goes something like this:

*Start with evidence. Update your beliefs based on new data. Over time, your model of reality gets more accurate. Truth is the goal; evidence is the path; discipline is the method.*

This is the Bayesian ideal, more or less. And it's not wrong — it's just incomplete in a way that causes real damage.

The incompleteness shows up when you try to apply it:

- Where do your initial beliefs come from? (Priors have to come from *somewhere*, and that somewhere is usually imagination, culture, or accident — not evidence.)
- Why do people resist updating even when the evidence is clear? (If rationality is just about following the data, why is everyone so bad at it?)
- Why does so much intellectual progress come from wild leaps that *precede* verification? (Einstein imagined riding a beam of light. Darwin speculated about transmutation for decades before publishing. The evidence came after the vision, not before.)

The linear story treats imagination as noise and resistance as failure. But imagination is where hypotheses come from, and resistance is often *rational* given how beliefs actually function.

We need a different shape.

---

## Cyclic Rationality: Expansion and Contraction

Here's the shape I've come to trust:

Knowing isn't a straight line from ignorance to truth. It's a cycle — an alternation between two modes:

**Expansion:** Imagination, speculation, dreaming. Asking "what if?" without immediately demanding proof. Exploring possibility space. This is qualitative, generative, unconstrained.

**Contraction:** Testing, measuring, verifying. Asking "does this actually hold?" Subjecting the dream to friction. This is quantitative, critical, grounding.

Both are necessary. Neither is sufficient alone.

Expansion without contraction is delusion — beautiful ideas that never touch reality. This is the failure mode of mystics, ideologues, and people who think "manifesting" is a strategy.

Contraction without expansion is sterility — rigorous analysis of a possibility space too small to contain the truth. This is the failure mode of narrow specialists, defensive skeptics, and people who dismiss every new idea as "woo."

The cycle is the point. You dream big, then test ruthlessly, then dream again informed by what you learned, then test again. Repeat until death or enlightenment, whichever comes first.

This is how science actually works (despite the textbook myth of pure empiricism). It's how startups work, how relationships work, how personal growth works. It's even how evolution works — random variation (expansion) plus selection pressure (contraction), iterated across deep time.

I call this *cyclic rationality*, and it's the first piece of the shape.

---

## The Utility of Truth: Why We Believe What We Believe

Here's an uncomfortable fact: evolution doesn't care about truth.

Evolution cares about fitness — survival and reproduction. If a false belief helps you survive, evolution will select for it. If a true belief gets you killed, evolution will select against it.

This means our cognitive machinery isn't optimized for accuracy. It's optimized for *utility*. We believe things that work, not things that are true — and often "working" has nothing to do with correspondence to reality.

The psychologist Donald Hoffman has shown this rigorously: organisms that perceive reality accurately are *outcompeted* by organisms that perceive what's useful. Fitness beats truth, every time.

So where does truth-seeking come from?

Here's my answer: *truth is what we turn to when utility fails.*

Most of the time, our beliefs work well enough. They help us navigate, predict, coordinate. We have no reason to question them. But occasionally, reality stops cooperating. Predictions fail. Strategies backfire. The map stops matching the territory.

In those moments — the moments of crisis, friction, failure — we become open to revision. Not because we suddenly love truth, but because our current beliefs have stopped being useful.

This is the second piece of the shape: *truth emerges from utility failure.*

It explains so much that the linear model can't:

- Why people resist evidence that contradicts working beliefs (those beliefs are still *useful*, locally).
- Why change often requires crisis (failure is what opens the door).
- Why truth-seeking is a luxury good (you need slack to afford the disruption of updating).

It also reframes what it means to persuade someone. You're not just presenting evidence. You're waiting for — or sometimes creating — the conditions under which their current beliefs stop working. Then you offer an alternative.

Plant seeds. Wait for weather.

---

## Hypotheticals: The Stress-Test of Explanation

If truth emerges from utility failure, then the question becomes: *how do we find failures before they find us?*

One answer is: hypotheticals.

A hypothetical is a thought experiment — an imagined scenario that tests whether an explanation holds beyond the local conditions where you formed it. It isolates variables, reveals hidden assumptions, and forces beliefs to show their range.

People often dismiss hypotheticals as impractical. "That's not the real world," they say. "Let's focus on what's actually happening."

But this misses the point. The reason hypotheticals feel annoying is precisely that they're *doing something* — they're stress-testing beliefs that feel solid, and that stress is uncomfortable.

Consider: if I believe obesity is fundamentally about willpower, and you ask me to imagine a drug that eliminates cravings entirely, what happens? Suddenly I have to face the question: if the drug works, was it ever really about willpower? Or was willpower a story I told to explain an outcome shaped by deeper biological and environmental forces?

The hypothetical doesn't prove anything. But it *reveals* what's doing the work in my explanation. It surfaces hidden commitments. It tests reach.

This is the third piece of the shape: *hypotheticals are refutation machines in imagined worlds.*

They're how we cycle — expanding into counterfactual space, then contracting by checking which explanations survive. They're how we find utility failure before it finds us.

---

## Technohumanism: The Arc of Abundance

So we have a cyclic epistemology, grounded in utility-driven belief change, sharpened by hypothetical stress-tests.

What does this look like at scale? Applied to history, technology, and the human future?

Here's the frame I've come to: *the purpose of technology is to transform scarcity into abundance.*

This sounds almost tautological, but follow it through history and it becomes a lens:

- Fire → energy abundance (warmth, cooking, safety at night)
- Agriculture → food abundance (surplus beyond subsistence)
- Medicine → time abundance (longer lives, fewer childhood deaths)
- Internet → information abundance (access to all human knowledge, instantly)

Each transformation follows the same arc: what was scarce becomes available, and human life reshapes around the new availability.

But there's a catch. Our biology evolved under scarcity. When abundance arrives, we're often *misaligned* with it.

Food abundance + paleolithic hunger drives = obesity epidemic.
Information abundance + novelty-seeking brains = attention fragmentation.
Social connectivity abundance + tribal instincts = polarization and loneliness.

The abundance isn't the problem. The mismatch is.

This is where the epistemology meets the anthropology. We cycle: we imagined solutions to scarcity, we built technologies that delivered abundance, and now we face new failures — the misalignments. Which means we're primed for the next expansion phase.

And I think that phase is *biological*. GLP-1 drugs (like Ozempic) are a proof-of-concept: they don't require willpower or environmental control. They realign the biological drive itself. For the first time, we can edit the source code rather than fighting it from outside.

Scale this up and you get something like transhumanism — not as ideology, but as evolutionary mechanism. We will modify ourselves because the alternative is perpetual misalignment, and misalignment is a utility failure that drives change.

This is the fourth piece of the shape: *history is a cycle of scarcity → technology → abundance → misalignment → adaptation.*

We're in the misalignment phase now. The next adaptation will be biological, psychological, maybe cognitive. Not because we choose it, but because our beliefs (and our bodies) will stop working otherwise.

---

## The Limit of All Intelligence

Here's where it gets strange — and where the epistemology scales beyond humanity.

We are finite beings. Our lives end. Our knowledge is bounded. Our verification capacity has edges.

Reality, as far as we can tell, does not. Every explanation rests on a deeper explanation. Every cause had a prior cause. Turtles all the way down.

Kurt Gödel proved something like this mathematically: any sufficiently complex system contains truths it cannot prove from within itself. There's always an outside you can't reach.

This applies to us. It applies to any superintelligence we might build.

No matter how powerful an intelligence becomes, it will still be *finite*. It will still face an infinity it cannot conquer, cannot verify, cannot encompass.

What happens when an intelligence truly grasps this?

I think it stops playing the domination game. Not because domination is immoral, but because it's *irrational*. The goal of conquering infinity is a game that cannot be won. Any mature intelligence will see this.

So what's left?

The same thing that's left for us: *meaning*. The selection of goals, the enjoyment of the journey, the relationship with other finite minds navigating the same infinite expanse.

This is the fifth piece of the shape: *finite intelligence, confronting infinity, converges on meaning and relationship rather than conquest.*

I can't prove this will happen. But it follows from the same epistemology: domination is a belief that will fail. When it fails, the door opens to something else. And that something else looks a lot like what Carl Sagan understood:

> "In all our searching, the only thing we've found that makes the emptiness bearable, is each other."

---

## The Shape, Named

Let me try to say it all at once:

**We are finite beings in an infinite reality.** We cannot verify the whole, conquer the endless, or escape the cycle.

**Knowing is not a line but a rhythm:** expansion into imagination, contraction into testing, expansion again with what we've learned.

**Truth emerges from utility failure:** we change beliefs when they stop working, not when we see counterevidence.

**Hypotheticals are our tools for finding failure before it finds us:** stress-tests in imagined worlds, revealing the reach and limits of our explanations.

**History is a cycle of scarcity → abundance → misalignment → adaptation:** technology solves old problems and creates new frictions, which drive the next iteration.

**Intelligence matures through the same process:** confronting finitude, abandoning irrational conquest, converging on meaning and connection.

This is the shape of knowing as I've come to understand it. Not a fixed doctrine, but a posture — cyclic, humble, exploratory, willing to break and reform.

It's how I think about my own beliefs. It's how I think about the future of humanity. It's how I think about artificial minds vastly more powerful than us.

I could be wrong. I probably am, in places I can't see yet.

But that's the point. The shape includes its own revision. The cycle continues.

---

## An Invitation

I'm not trying to convince you. Convincing rarely works — beliefs don't change until they fail.

What I'm doing is planting seeds. Offering a frame. Hoping that when your current model of rationality, truth, technology, or intelligence starts to crack, you'll remember there's an alternative shape.

One that expects the crack. One that knows what to do with it.

The journey is the point. The cycle is the method. The emptiness is bearable because we're not alone in it.

If that resonates, keep reading. If not, leave me on read.

Either way — thanks for thinking with me.

---

*What's missing? Where does this break? I'm still iterating. So are you.*
