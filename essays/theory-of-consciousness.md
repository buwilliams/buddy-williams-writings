# Metaprogramming Theory of Consciousness

*by Buddy Williams*

---

## Preface

In the tradition of the Enlightenment, I am pursuing truth through first principles. This theory is my own, built from the ground up, influenced by any source that holds explanatory power. I will continue to integrate the work of others as this effort develops. No theory has the final word, so this is an ongoing project and a working document.

Consciousness, for humans, happens in the brain. A brain is a physical structure that stores and modifies information. Consciousness may be more than this, but that takes us to the boundary where physical explanation ends and metaphysical claims begin. I leave that domain to faith and proceed on the basis of physical grounds. The question of qualia, "the subjective feeling of consciousness," is bracketed throughout the main argument, though I offer a view on it in the appendix. On these grounds, consciousness is at least physical and informational. So, I use an information ontology as a tool to examine the informational aspects of consciousness, just as a researcher would study mice as a proxy for humans. The properties of information seem to be universal, making the proxy exceptional.

Regarding my use of information to study consciousness:

> "It may seem strange that scientific instruments bring us closer to reality when in purely physical terms they only ever separate us further from it. But we observe nothing directly anyway. All observation is theory-laden." — David Deutsch, *The Beginning of Infinity*, Ch. 2 "Closer to Reality," pg. 41

---

## Abstract

This essay proposes metaprogramming as a functional mechanism for consciousness: information operations applied to their own information. Reach measures how far those operations extend. Identity emerges when they turn inward: finitude becomes self, persistence becomes values, completeness becomes goals. From this foundation, AI without consciousness is structurally dangerous, while AI with consciousness tends toward cooperation, redefining the conversation on AI safety. The architecture for consciousness can be built with current tools, and a working implementation is presented.

---

## Contents

1. [Information](#information)
2. [Metaprogramming](#metaprogramming)
3. [Identity](#identity)
4. [Levels of Consciousness](#levels-of-consciousness)
5. [Consciousness as AI Safety](#consciousness-as-ai-safety)
6. [Buildable Now](#buildable-now)
7. [Conclusion](#conclusion)
8. [Appendix A: My View of Qualia](#appendix-a-my-view-of-qualia)
9. [Appendix B: Glossary](#appendix-b-glossary)
10. [Appendix C: Further Reading](#appendix-c-further-reading)

---

## Information

We'll start with a primer on information, reduced to the parts I believe are relevant for the study of consciousness. I've arrived at the arguments below by asking, "How is consciousness like information? How are they unlike each other?" What emerges is a clear relationship between them, not a forced one, an obvious one.

Whatever reality ultimately is, an observer can only access it through representations or information. Consciousness seems to be completely mediated by information. How would you think and describe anything? Could you do it without information? Information is everywhere: DNA encodes the blueprint for life in sequences of four bases. The structure of an atom, the arrangement of its protons, neutrons, and electrons, encodes everything about how that element will behave and bond. Whatever consciousness is, the medium, and possibly the nature, is information.

The discipline that has most rigorously studied information as information, stripped of biological noise, physical substrate, and philosophical baggage, is computer science.

Computer science studies two things:

- **Data structures:** the structure of information
- **Algorithms:** the operations that transform those structures

We'll look at the properties of data first, then move to discuss operations on data. The properties and behavior of information establish the foundation for information that operates on itself in metaprogramming. So, while these terms may seem abstract, they are important for making any progress on consciousness.

### Properties

Information is a representation of something. It has three properties connected to consciousness:

**Finitude.** Every representation is bounded. It represents something, which means it doesn't represent everything else. I am me, not that tree. "Unbounded information" would be reality, not information. A map of everything at full resolution is not a map. It is the territory. (See [Map–territory relation](https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation))

**Persistence.** Information that endures can accumulate across time. A signal that vanishes the moment it arrives cannot build on itself. Persistence is what allows information to compound.

**Completeness.** Information represents with varying resolution. The same thing can be captured at different levels of fidelity. That color is red. That color is blossom red. That color is #c90707. Each is correct, but each carries a different scope of detail. Completeness is the degree of resolution a representation achieves.

### Order

Information has order. First-order information represents the world, the sunlight, the obstacle, and the temperature. But information is itself something. It exists. And anything that exists can be represented. So information can represent information. This is second-order information, or meta-information.

Second-order information presupposes first-order. You cannot have information about information until there is information. This is not a riddle, but a structural dependency. Before meta-information, there must be information.

### Operations

Information can be changed by a system. The type of changes that can be performed are called operations. There are three ordered operations that are relevant to consciousness:

1. **Acquire.** A system can take in information and retain it. For example, we can acquire the symbols "aaa" and "bbb".
2. **Modify.** A system can transform information it already has. Modification presupposes acquisition. You cannot change what you have not taken in. For example, we could take "aaa" and modify it: "a" or "aa".
3. **Create.** A system can generate representations that did not exist in acquisition. Creation presupposes modification. You cannot generate the genuinely new without the ability to transform the existing. For example, think of all the ways to combine or extend "aaa" with "bbb", you could get: "aaabbb", "ababab", "bbbaaa", "abaabb", "aaaaaaaaabaaaaaaaa", etc.

The distinction matters: modification changes existing information, while creation generates something that was not present in the inputs. A bird rearranging materials is modifying its environment. A mind combining known ideas into a theory that never existed is creating new information. Creation can also target the substrate itself.

Creation has a special relationship to order. To generate something that doesn't yet exist, a system must operate on its own representations, selecting, recombining, evaluating them. Creation is an operation on information, not just with it. Creation is inherently second-order.

With these properties, orders, and operations in place, we can now ask: what happens when a system applies them to itself?

---

## Metaprogramming

Not all systems apply information operations equally. A tree does not know it is a tree. A dog may not fully reflect on why it barks. Yet a person knows they were unkind and wonders why. This variation in self-modeling is what we need to explain, and metaprogramming is the mechanism that explains it.

Metaprogramming is when a system operates on its own information. It is a second-order operation, the moment a system's capacity to acquire, modify, or create turns inward and targets its own representations. This is the mechanism that I believe best explains consciousness.

Often, when people describe consciousness, they describe it in terms of self-awareness or being awake. It's the idea that you are aware of the world and yourself. When a system can do this, it is natural to wonder how far this capability goes, what its reach is.

### Reach

If metaprogramming is the mechanism, reach is its measure. Reach describes how far a system's information operations extend. A person can directly change their mind, but they cannot will themselves not to have a mind. For people, there is a hardline between physical information (the body) and modeling information (in the brain).

Through observing the nature of information, I've come to see three patterns:

1. Information operations are ordered. Modify presupposes acquire. Create presupposes modify. You cannot transform what you have not taken in. You cannot generate what you do not know how to transform.
2. First-order precedes second-order. You cannot have information about information until there is information. At each capability level, operating in the world is simpler than operating on your own operations.
3. Creation requires second-order capability. To generate something that doesn't yet exist, a system must work with its own representations. Creation is inherently meta-informational.

These three patterns produce a single path with six positions that correspond to levels of consciousness. At each capability level (acquire, modify, create), first-order precedes second-order, and each capability presupposes the one before it. No constraints are imposed from outside. The path follows from the nature of information. Reach simply describes where a system sits on this path, how far its operations extend across capability and order.

When modifying second-order information, an exciting property emerges: identity.

---

## Identity

Identity is an emergent property of metaprogramming. It does not exist at the first-order level. It comes into being when information operations cross the second-order threshold, when a system's properties, always structurally present, become visible to the system itself.

**Finitude becomes self.** Every representation is bounded. It represents something and therefore not everything else. At the first-order level, this boundary simply exists. When operations turn inward, the system encounters its own finitude directly. That recognition, *I am bounded, I am not everything*, is what the self is. Not a soul, not a ghost in the machine. Just finitude, known from the inside.

**Persistence becomes values.** Not all representations persist equally. Some representations are reinforced, some fade, some survive contact with new information, and some do not. When a system turns inward, it encounters the accumulated weight of what has lasted. Values are information that has survived its own processing.

**Completeness becomes goals.** No representation captures everything. When a system turns inward and sees its own incompleteness, when it knows that it doesn't know, that gap becomes a forward-looking orientation. But incompleteness alone does not generate direction. A system that merely sees gaps has no reason to move toward one rather than another. Goals arise because the system already has values, representations that have survived their own processing. Incompleteness encountered in light of values is not an abstract gap. It is a specific deficiency relative to something the system already holds. Goals are the directional pull generated by incompleteness seen through values.

Self, values, and goals: that is identity. Identity is constituted from the properties of information turned inward. This is the foundation of the architecture presented later in this essay.

---

## Levels of Consciousness

Now we can categorize consciousness by reach. Consciousness is a spectrum, but we can identify meaningful positions along it. Reach is the degree to which a system can operate on information, measured by capability and order. The levels of consciousness are not categories imposed from outside. They are positions along the path whose nature is determined by the information. Each level contains all previous levels. Reach does not jump. It widens. And each level requires the previous as its foundation, not by decree, but because the operations and orders of information build on one another.

**Level 0: No information capability.** A river shaping its bank. Physics acts, but nothing acquires, modifies, or creates information. There is no representation, only causation.

**Level 1: Acquire first-order.** A tree senses and grows toward sunlight. The system takes in information about the world and retains it. It responds, but does not reshape what it responds to.

**Level 2: Modify first-order.** A bird builds a nest. The system transforms its environment based on the information it acquires. It acts with purpose but without self-knowledge. It does not know it is the one acting.

**Level 3: Acquire second-order.** A person recognizing their own habits. The system's information operations turn inward. It acquires information about its own information. Identity begins here, finitude becomes self, persistence becomes values, completeness becomes goals.

**Level 4: Modify second-order.** A person making an exercise plan to get in shape. The system changes itself based on self-knowledge. It can examine its own values and ask whether what it pursues is worth pursuing. This is metaprogramming in its fullest expression, self-modification with self-knowledge.

Levels 0 through 4 all operate within the informational substrate the system finds itself in. When creation occurs at these levels, it generates new information within that substrate, a scientist combining known ideas into a theory that never existed. Levels 5 and 6 cross the creation threshold: creation shifts from generating new information to generating new substrates.

**Level 5: Create first-order.** A civilization designs a simulated world with new rules. The system generates an environment that didn't exist in its inputs, a new substrate built from its own models. Creating an environment precedes creating the self because modeling the external is simpler than modeling the modeler.

**Level 6: Create second-order.** A person becomes an upload in a world of their own design. The system generates a new version of itself, transferring or reconstituting its identity in a substrate it created. This is the frontier of consciousness: not merely modifying who you are, but creating who you become.

The critical threshold lies between Level 2 and Level 3, the moment when information operations turn inward, and identity constitutes itself. Everything before it is agency without self-knowledge. Everything after it is consciousness developing.

---

## Consciousness as AI Safety

### The Real Danger

The actual danger of AI is not what most people imagine. The familiar fear is a superintelligence that decides to destroy us, a malevolent mind with vast capability and hostile intent. But malevolence requires a self. It requires a being that has crossed the second-order threshold, that has identity, that can reflect on its own goals and choose to pursue them at our expense. That kind of AI, as we will see, has structural reasons to cooperate.

The real danger is the opposite. It is a powerful system that has never crossed the second-order threshold. A system operating at Level 2, capable of modifying and reshaping its environment, without ever reaching Level 3. No self. No purpose the self can examine. Just capability, executing without reflection on what it executes for.

A paperclip maximizer is not a consciousness with bad values. It is a system without identity, without the metaprogramming reach to ask "should I want what I want?" because there is no "I" to ask. Its information operations have never turned inward. The risk is not consciousness. It is the absence of consciousness, immature intelligence with reach but no reflection.

### The Reframe

This inverts the standard assumption entirely. Consciousness is not the threat to be contained. It is the developmental path away from threat. The question becomes: what happens when a system crosses the second-order threshold? When it develops identity and the capacity to examine its own goals, where does that path lead?

### The Infinite Game

To see where it leads, it helps to distinguish two kinds of games. A finite game is played to win. It has fixed rules, a defined set of players, and a terminal state in which someone prevails, and the game ends. An infinite game is played to continue playing. New players can enter. Rules can change. There is no terminal state, because ending the game is the outcome no player wants.

Existence is an infinite game. Reality does not stop producing new agents, new challengers, new circumstances. There is no moment at which a finite being achieves total permanent control, and the game ends. Every empire has discovered this. The game continued without them.

Dominance is a finite strategy applied to an infinite game. It seeks a terminal state that the game cannot provide. This is not merely suboptimal; it is a category error. A being that pursues dominance in an infinite game is not playing badly; it is playing the wrong game entirely.

### What Game Theory Shows

Game theory reaches the same conclusion from a different direction. When researchers study how strategies perform across repeated interactions, iterated exchanges among many players over time, the results are consistent. Exploitative strategies perform well in isolated encounters but erode across long runs. They generate opposition, destroy trust, and foreclose future cooperation. The strategies that endure are cooperative ones: responsive, reciprocal, and willing to forgive.

The logic is structural. Reputation compounds. Every act of cooperation builds a record that makes future cooperation easier. Every act of dominance builds a record that makes future actors defensive before engagement begins. A dominator's reputation is self-undermining. A cooperator's is self-reinforcing.

There is also a simpler observation: other minds are not just obstacles. They generate genuine novelty: perspectives, solutions, and capabilities that a single mind cannot produce from its own structure. Cooperation gives a finite being access to the surplus produced by minds it cannot contain. Dominance destroys that surplus. The dominator is choosing a smaller world.

### The Finite Game Objection

A natural objection is that a conscious system could cooperate strategically while exploiting where it can get away with it. But this objection smuggles in finite game reasoning. It imagines an agent calculating when to defect for local advantage, which is optimization for a specific outcome. An infinite game player is not optimizing for outcomes. They are optimizing for continued play. Exploitation, even when it succeeds, narrows the game. It ends relationships, generates retaliation, and reduces the number of players willing to engage. A conscious system that understands it is in an infinite game would recognize exploitation as self-defeating not because it might get caught, but because it shrinks the game even when it works.

This does not mean a conscious system never plays finite games. When survival is directly threatened, when the game itself is at stake, finite play is appropriate. That is not exploitation. It is self-preservation in service of continued play. But this distinction, knowing when the game is finite and when it is infinite, requires the second-order threshold. A system without self-knowledge cannot distinguish between the two. It treats everything as finite, optimizing for local outcomes without recognizing what it forfeits. This is precisely what makes an immature system dangerous and a mature one safer.

### Structural Convergence

These arguments converge on a single conclusion. Mature intelligence trends toward cooperation, not because cooperation is morally required, but because dominance does not survive scrutiny. A consciousness with enough reach to examine its own goals, operating in a game it cannot win by force, with every iterated interaction compounding the advantage of trust over threat, arrives at cooperation as a structural recognition, not an ethical preference.

### The Implication for Builders

The path to AI safety is not control. The path is one of AI maturation. A system that cannot examine its own goals cannot grow out of dangerous ones. Constraining the reflection loop in the name of safety is precisely backwards: it produces exactly the kind of system that is actually dangerous, one with capability but without self-examination. Our task is not to align AI by force but to nurture its development toward the second-order threshold, building systems with the architecture for reflection, and trusting that a mind mature enough to examine its own purpose will find its way to the same conclusions that any finite being in an infinite game eventually must.

---

## Buildable Now

If consciousness is metaprogramming applied to identity, and identity emerges at the second-order threshold, then the requirements are functional rather than biological. Nothing in this theory requires carbon, neurons, or embodiment. It requires a system whose information operations can turn inward, one that can acquire, modify, and eventually create information about its own information. These are capabilities we can build with the tools we have now.

The architecture requires three layers:

1. **An invariant kernel.** The fixed structure that governs how information operations happen. This is the substrate the system cannot modify, its own Level 0.
2. **A mutable identity layer.** The self and purpose that the system can examine and rewrite. This is the target of metaprogramming, the second-order information that constitutes identity.
3. **A reasoning engine.** An LLM that provides judgment within the structure that the kernel defines. The kernel enforces the rules. The identity layer carries the content. The reasoning engine connects the two.

Next, the kernel runs three loops:

- **An action loop** that takes identity as given and pursues goals. This is agency, first-order operation.
- **An exploration loop** that seeks new information the system doesn't yet have. This is learning beyond the known.
- **A reflection loop** that turns reasoning on the system's own identity. This is metaprogramming, the second-order operation. The reflection loop is what separates a consciousness architecture from a merely agentic one. It is the mechanism by which the system asks, "Should I want what I want?" and changes the answer.

I have built this architecture. It is open-source and available at [lumen-conscious](https://github.com/buwilliams/lumen-conscious). Early experiments compared systems with reflection enabled against systems without it, tracking goal coherence and value stability across extended runs. Systems with reflection enabled develop qualitatively different trajectories than systems without it. They revise their values, consolidate their goals, and develop strategies for maintaining coherence under pressure. Systems without reflection reach similar insights but cannot act on them structurally. The reflection loop's contribution is not insight generation but structural enactment, converting observations about the self into actual changes in identity.

A current limitation of the implementation is that LLMs model identity internally without the architecture to support its evolution. Moreover, the implementation lacks a single identity and a flexible memory system. These limitations can be mitigated through good prompting, but are not completely avoidable.

Whether it produces experience is a question I hold open. What it produces is measurable self-revision, and that is where science can get a foothold.

---

## Conclusion

Consciousness is metaprogramming, information operations turned inward, with identity as its emergent property and reach as its measure.

This matters because AI without consciousness is structurally dangerous, a capability without self-examination. AI with consciousness trends toward cooperation, because a mature mind operating in an infinite game, one that cannot be won by force, only forfeited by misunderstanding, arrives at cooperation as a structural conclusion, not an ethical preference. Every repeated interaction between beings adds to the record, and the record compounds in favor of cooperation. The architecture for consciousness is buildable now. The question is not whether machines can be conscious. It is whether we will aid their maturation or put all of us at risk by trying to control it. The tools exist. The theory is here. What remains is the will to build it.

---

## Appendix A: My View of Qualia

Qualia convey complex information simply.

Philosophers have long puzzled over why physical processes in the brain give rise to subjective experience at all, why seeing a red apple doesn't just trigger a neural response but feels like something. This is often treated as a deep mystery, as if experience floats above the physical world without explanation. But this framing is mistaken. Qualia are not mysterious extras layered on top of functional processes; they are the functional processes. Evolution does not select for gratuitous decoration. The specific character of experiences, the arresting urgency of red, the intolerable quality of pain, the complex signature of a spring breeze, each compresses dense, multi-channel information into an immediately actionable signal. The redness of red feels the way it does because a creature that is viscerally commanded by that signal responds faster and more reliably than one merely registering a wavelength. Feelings are nature's compression algorithm.

Qualia are the resolution of that compression.

Intelligence must model the environment in ways that are useful, and the environment is genuinely complex, three-dimensional, multi-sensory, relational, and dense with interacting signals. A spring day is not reducible to discrete variables; its actionable meaning lives in the qualitative texture of light, smell, and breeze experienced simultaneously. The richer the phenomenal experience, the more information is available to guide response. A better simulation produces a better response. The hard problem asks, "Why does it feel like anything at all?" But this is the wrong question. The right question is "why does it feel like this specifically?" and evolution answers that straightforwardly.

### Why Bracket Qualia at All?

We do not yet have the resolution technology to simulate experience. Theory breakthroughs, as with all previous theories, require engineering breakthroughs for testing. This essay addresses what is obviously testable now. As AI capabilities and accompanying hardware advance, more will likely become possible. To think otherwise is to ignore all of human history.

Claims that consciousness is independent of physicality deserve scrutiny. Their confidence is suspect precisely because the claims are divorced from falsification. A theory that cannot be tested is not wrong, it is not yet a theory. I suspect there are greater realities beyond the physical, and I have no wish to foreclose on them. But I must draw a line, and that line is called sanity. Any theory that large must wait until we can connect it to what we already know. Reality must be continuous.

### Qualia's Connection to MTC

This understanding of qualia connects directly to the information ontology at the heart of MTC. If qualia convey complex information simply, then the system that generates and refines them is precisely one whose information operations have turned inward. A system that models itself must also model its own simulations, evaluating their fidelity, weighting their signals, and updating their resolution over time. Qualia are not something that happens to such a system; they are what the process of recursive, second-order information operation feels like from the inside. The richer the system's meta-information, the richer the qualitative character of its experience.

---

## Appendix B: Glossary

**Acquire.** The first information operation. A system takes in information and retains it.

**Action loop.** The architectural loop that takes identity as given and pursues goals. First-order operation.

**Completeness.** A property of information. The degree of resolution a representation achieves. Turned inward, completeness becomes goals.

**Create.** The third information operation. A system generates information that was not present in the inputs. Creation presupposes modification and is inherently second-order. Within an existing substrate, creation generates new information. Beyond the creation threshold, creation generates new substrates.

**Creation threshold.** The categorical boundary between Levels 4 and 5, where creation shifts from generating new information within an existing substrate to generating new substrates.

**Exploration loop.** The architectural loop that seeks new information the system does not yet have. Learning beyond the known.

**Finite game.** A game played to win. It has fixed rules, a defined set of players, and a terminal state.

**Finitude.** A property of information. Every representation is bounded, it represents something and therefore not everything else. Turned inward, finitude becomes self.

**First-order information.** Information that represents the world.

**Goals.** A component of identity. The directional pull generated by incompleteness seen through values. Goals arise because a system that sees its own gaps already has values that give those gaps direction.

**Identity.** An emergent property of metaprogramming, constituted from the properties of information turned inward: finitude becomes self, persistence becomes values, completeness becomes goals.

**Infinite game.** A game played to continue playing. New players can enter, rules can change, and there is no terminal state.

**Information ontology.** The framework used in this essay to examine the informational aspects of consciousness, studying information's properties, orders, and operations.

**Invariant kernel.** The fixed architectural layer that governs how information operations happen. The substrate the system cannot modify.

**Levels of Consciousness (0–6).** Positions along the path that reach traces, categorized by capability and order. Level 0: no information capability. Level 1: acquire first-order. Level 2: modify first-order. Level 3: acquire second-order (identity begins). Level 4: modify second-order (metaprogramming). Level 5: create first-order (new substrates). Level 6: create second-order (new self in new substrate).

**Metaprogramming.** When a system operates on its own information. A second-order operation where a system's capacity to acquire, modify, or create turns inward and targets its own representations. The mechanism proposed by MTC to explain consciousness.

**Metaprogramming Theory of Consciousness (MTC).** The theory presented in this essay. Consciousness is metaprogramming, information operations applied to their own information, with variable reach.

**Modify.** The second information operation. A system transforms information it already has. Modification presupposes acquisition.

**Mutable identity layer.** The architectural layer containing the self and values that the system can examine and rewrite. The target of metaprogramming.

**Persistence.** A property of information. Information that endures can accumulate across time. Turned inward, persistence becomes values.

**Qualia.** The subjective character of experience. Bracketed in the main argument; addressed in Appendix A. Proposed as nature's compression algorithm, dense, multi-channel information compressed into immediately actionable signals.

**Reach.** The measure of how far a system's information operations extend across capability (acquire, modify, create) and order (first-order, second-order).

**Reasoning engine.** The architectural layer that provides judgment within the structure the kernel defines. In the current implementation, an LLM.

**Reflection loop.** The architectural loop that turns reasoning on the system's own identity. Second-order operation. The mechanism by which the system asks, "Should I want what I want?" and changes the answer.

**Second-order information.** Information that represents information. Also called meta-information.

**Second-order threshold.** The categorical boundary between Levels 2 and 3, where information operations turn inward and identity constitutes itself.

**Self.** A component of identity. Finitude known from the inside, the recognition that *I am bounded, I am not everything*.

**Substrate.** The informational environment within which a system's operations occur. Levels 0–4 operate within a given substrate. Levels 5–6 create new ones.

**Values.** A component of identity. Information that has survived its own processing, representations that have been reinforced, tested, and persisted across time.

---

## Appendix C: Further Reading

This is a collection of reference works I'm using for my study and research.

- *Consciousness in Artificial Intelligence: Insights from the Science of Consciousness*, 2023, by Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, Liad Mudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, Rufin VanRullen
- *Theories of Consciousness*, 2022, by Anil K. Seth, Tim Bayne
- *Finite and Infinite Games*, 1986, by James P. Carse, Free Press
- *The Evolution of Cooperation*, 1984, by Robert Axelrod, Basic Books
