# The Orthogonality Thesis is Practically Wrong

*Why pure philosophy and complex reality diverge on AI risk*

**Buddy Williams** · September 18, 2025 · [Originally posted on X](https://x.com/BuddyIterate)

---

The orthogonality thesis is correct in a pure sense, but incorrect in a practical/reality sense.

I see the social situation as two adversarial purposes/groups at work:

1. **People that explore the pure philosophy of intelligence** — who rightly approximate AI risk via the orthogonal thesis
2. **People that build AI in the real-world**

The first group acts as an **immune system** for the second group. This is good because we do not want to build the Torment Nexus.

---

## Why the Thesis is Practically Wrong

The orthogonality thesis is practically wrong since the thesis is developed in a pure thought space outside the complexity of reality.

Where I depart from these thinkers is in their absolute declarations such as:

> "If anyone builds it, everyone dies."

In my view, **this is false**.

---

## Evidence: The Nature of Reality is Complex

My evidence beyond exploring typical Bayesian priors is an argument about the nature of reality — namely, it's complex:

1. **Irreducible computation** — I lean toward the irreducible computation principle from Stephen Wolfram in Ruliology, who pioneered research about complexity.

2. **Simulation argument** — I find merit in the simulation argument since computation seems a better fit for reality than other models.

3. **The immune system is working** — The immune system group is having its intended effect. This immune group must be, by definition, adversarial and somewhat delusional — otherwise they may lack the appropriate motivation to keep us healthy. As an alternative to true delusion, they may also project delusion as a manipulation tactic. This last method seems to belong to the most intelligent among us.

---

## Conclusion

Is it possible we build the Torment Nexus? **Yes.**

Is it guaranteed? **No.**

I'm personally optimistic.
